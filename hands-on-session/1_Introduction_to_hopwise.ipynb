{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cEmoqMz6JIO"
   },
   "source": [
    "# üöÄ Introduction to Hopwise Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rjvqZQz8FUM"
   },
   "source": [
    "In this notebook, you'll explore how the Hopwise library works, its core components, and how to use it effectively in your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzkYC6iBFl06",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ‚öôÔ∏è Setup Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeB_cQUUFo0C"
   },
   "source": [
    "Before starting let's prepare our workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lf06KzClGN6L"
   },
   "source": [
    "1. Import the necessary module to access Google Drive from Colab and mount you Google Drive to the Colab enviroment. This allows you to access files and folders stored in your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fj_m2BywHU4F",
    "outputId": "a53053dd-5431-4b20-f55e-509b8465eb17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu5W7zIEJbn3"
   },
   "source": [
    "2. Install the `hopwise` libray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QpZTiUmPPED8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install hopwise[cli]\n",
    "!uv pip install \"dgl>=2.4.0\" -f https://data.dgl.ai/wheels/torch-2.4/cu124/repo.html --no-deps  # for KGAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4hKM7nlKXdG"
   },
   "source": [
    "3. Verify if the hopwise library has been installed correctly, running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "NdVCWNn-Le3T",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv run hopwise train --epochs=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT1KKNUYyD93"
   },
   "source": [
    "4.  To view the installed libraries in the right sidebar, run the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T-87OVPzyD93"
   },
   "outputs": [],
   "source": [
    "!ln -s /usr/local/lib/python3.11/dist-packages /content/dist-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKcPJmmd9NTH"
   },
   "source": [
    "5. To check if you are using the GPU, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd8kPaPB9Omd",
    "outputId": "4121673b-4ffc-42d3-8516-39a8ac6c0ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA device is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device_id = torch.cuda.current_device()\n",
    "    device_name = torch.cuda.get_device_name(device_id)\n",
    "    print(f\"CUDA Device ID: {device_id}\")\n",
    "    print(f\"CUDA Device Name: {device_name}\")\n",
    "else:\n",
    "    print(\"No CUDA device is available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50TCSDm3ANsH",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## üèóÔ∏è Framework Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxbGxMSxyD94"
   },
   "source": [
    "<div style=\"background-color: #fff8e1; border-left: 5px solid #ffc107; padding: 16px 20px; margin: 15px 0; border-radius: 8px; box-shadow: 0 2px 5px rgba(0,0,0,0.05); font-family: sans-serif; line-height: 1.6;\">\n",
    "  <p style=\"margin: 0;\">\n",
    "    <b>üöÄ</b>\n",
    "    <b>Hopwise</b> is an advanced extension of the <a href=\"https://recbole.io/index.html\" target=\"_blank\">RecBole</a> library, designed to enhance recommendation systems with the power of <b>knowledge graphs</b>.\n",
    "    By integrating <b>knowledge embedding models</b>, <b>path-based reasoning methods</b>, and <b>path language modeling approaches</b>, hopwise supports both <b>recommendation</b> and <b>link prediction</b> tasks with a focus on <b>explainability</b>.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNrK3G3KAUPf"
   },
   "source": [
    "The hopwise library follows a modular design, where each module named layer, is dedicated to a specific task to ensure clarity, reusability, and ease of maintenance. The library consists of **four** modules:\n",
    "* **Data and Configuration Management**: Manages the full lifecycle of data processing and experiment setup, including loading, preprocessing, sampling, and configuration management.\n",
    "* **Model**: Defines and implements various recommender algorithms\n",
    "* **Evaluation**:Includes different evaluation protocols\n",
    "* **Utilities**: Defines auxiliary functions and helpers for managing the pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka5GMVmEWP-M"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mallociFrancesca/XAIKGRLGM/a77f9ea5633475efe43038ef2a11e1341342e0ef/hands-on-session/hopwise-architecture.png\" alt=\"Model Execution Interfaces\" width=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_33H5uieA10T"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToMwnVgIy_rw",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mode Execution Interfaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "collapsed": true,
    "id": "a5JaOwbK0sox",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "98ea82c7-1615-473a-862c-3efc8c93ab0a"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mallociFrancesca/XAIKGRLGM/a77f9ea5633475efe43038ef2a11e1341342e0ef/hands-on-session/hopwise-interfaces.png\" alt=\"Hopwise Interfaces\" width=\"600\" height=\"350\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6bPreBX5xAa"
   },
   "source": [
    "Hopwise supports two main interfaces for running recommendation models:\n",
    "\n",
    "* üñ•Ô∏è **Command-Line Interface (CLI)**: the entire pipeline can be directly executed from the command line by running the command `uv run run_hopwise.py` with the desired arguments (e.g.,`-‚Äìparameter_name=[parameter_value]`).\n",
    "\n",
    "* üêç **Python API Interface**: the entire pipeline can be programmatically executed by invoking functions and classes directly in Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NTizx6d9lZB",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The entry Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCkkL1Hz8pOb"
   },
   "source": [
    "The entry point of Hopwise is the method  `run_hopwise()` located in: [hopwise/quick_start/quick_start.py](https://github.com/tail-unica/hopwise/blob/main/hopwise/quick_start/quick_start.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqHkKrpRVbDA"
   },
   "source": [
    "The `run_hopwise()` method manages the entire recommendation pipeline with the following workflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8u4Qg-2wA10U"
   },
   "source": [
    "```yaml\n",
    "Configuration ‚Üí Dataset ‚Üí Model ‚Üí Training ‚Üí Evaluation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLPZsvD0f38i"
   },
   "source": [
    "The `run_hopwise()` manages the entire recommendation pipeline through a structured 7-steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "UlxwiXJP5358",
    "outputId": "c0115647-aa50-4532-f3ae-7f9da97db83a"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mallociFrancesca/XAIKGRLGM/a77f9ea5633475efe43038ef2a11e1341342e0ef/hands-on-session/quick-start.png\" alt=\"Quick Start Diagram\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtiGYuEq0n3V"
   },
   "source": [
    "\n",
    "1. **Configuration**  \n",
    "   Initializes a unified configuration object by combining model and dataset settings. This object governs the entire pipeline.\n",
    "\n",
    "2. **Dataset Creation**  \n",
    "   Loads and preprocesses the dataset based on the configuration, applying necessary filtering and formatting.\n",
    "\n",
    "3. **Dataset Preparation**  \n",
    "   Splits the dataset into training, validation, and test sets according to the configuration specified in the Config object.\n",
    "\n",
    "4. **Model Initialization**  \n",
    "   Selects the model class (e.g., general_recommender, etc) specified in the configuration.\n",
    "\n",
    "5. **Trainer Setup**  \n",
    "   Selects and initializes the appropriate trainer class based on the task type and model.\n",
    "\n",
    "6. **Training**  \n",
    "   Runs the training process using the training and validation datasets, optionally displaying progress and saving intermediate results.\n",
    "\n",
    "7. **Evaluation**  \n",
    "   Evaluates the trained model on the test set and returns performance metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZUo350yAzUa"
   },
   "source": [
    "## 1Ô∏è‚É£  Configuration Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1eQDKTaA7W_"
   },
   "source": [
    "The Hopwise pipeline is controlled via a set of **configurations** grouped into several categories:\n",
    "\n",
    "- **Environment settings**\n",
    "- **Data settings**\n",
    "- **Training settings**\n",
    "- **Evaluation settings**\n",
    "\n",
    "The configurations are assigned via the Configuration module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "nsDueupe6Qkj",
    "outputId": "99a4e09e-eff4-4e4d-82a4-9c40042a4077"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/mallociFrancesca/XAIKGRLGM/a77f9ea5633475efe43038ef2a11e1341342e0ef/hands-on-session/configuration-management.png\" alt=\"Configuration Management\" width=\"600\" height=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9qMlrsYCL_H"
   },
   "source": [
    "### Ways to Provide Configuration Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrmEH1ToHic8"
   },
   "source": [
    "Hopwise supports three methods for defining these configurations:\n",
    "\n",
    "1. **Configuration File**  \n",
    "   You can define all settings in a `.yaml` file and pass it to `run_hopwise.py` using the `--config_files` argument.\n",
    "\n",
    "2. **Command-Line Arguments**  \n",
    "   Configuration parameters can be passed directly as command-line arguments (e.g.,`-‚Äìparameter_name=[parameter_value]`) when executing the script, overriding defaults or YAML values.\n",
    "\n",
    "3. **Parameter Dictionary**  \n",
    "   When using the API (i.e., running models programmatically in Python), you can provide configurations as a Python dictionary object (e.g., `parameter_dict = {'parameter_name':parameter_value}` ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USFDbjd5CYDu"
   },
   "source": [
    "The way you provide configuration settings in Hopwise depends on the interface you're using:\n",
    "\n",
    "`üñ•Ô∏è Command-Line` or  `üêç Python API`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPa64tCQA10V"
   },
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\">\n",
    "<b>üìå </b> <b>Note</b> <br>\n",
    "Hopwise supports the combination of three types of parameter configurations.<br><br>\n",
    "The priority of the configuration methods is: <br>\n",
    "<code>\n",
    "Command Line > Parameter Dicts > Config Files > Default Settings\n",
    "</code>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZz6IBzqA10V"
   },
   "source": [
    "Based on the two main modes interfaces:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPc4v7ZCxSXh",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **üñ•Ô∏è Command-Line Interface (CLI)**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51C_AkStA10V"
   },
   "source": [
    "\n",
    "When running hopwise from the terminal (e.g., using `run_hopwise.py`), you can configure the system in two ways:\n",
    "\n",
    "1. **Command-line Arguments**  \n",
    "  Example:\n",
    "\n",
    "  ```bash\n",
    "  uv run run_hopwise.py --model=BPR --dataset=ml-100k --learning_rate=0.01\n",
    "  ```\n",
    "\n",
    "2. **Config file(s)**\n",
    "  \n",
    "  Example:\n",
    "  \n",
    "  * Create a `.yaml` file named `config.yaml` file, and include the settings:\n",
    "    ```yaml\n",
    "    model: BPR\n",
    "    dataset: ml-100k\n",
    "    learning_rate: 0.01\n",
    "    ```\n",
    "  * Run the following command:\n",
    "    ```bash\n",
    "    uv run run_hopwise.py --config_files=config.yaml\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZabqHFjcwPzF",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "#### **üêç Python API Interface**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8o-ZJXCCGgO"
   },
   "source": [
    "When running hopwise in a Python script, you can configure the system in two ways:\n",
    "\n",
    "\n",
    "1. **Parameter dictionary**:\n",
    "    ``` python\n",
    "    # Define a dictionary with configuration settings\n",
    "    config = {\n",
    "        'model': 'BPR',\n",
    "        'dataset': 'ml-100k',\n",
    "        'learning_rate': 0.01\n",
    "    }\n",
    "    # Execute the recommendation pipeline using the specified configuration\n",
    "    run_hopwise(config_dict=config)\n",
    "    ```\n",
    "\n",
    "2. **Config file(s)**:\n",
    "\n",
    "  * Create a `.yaml` file named `config.yaml` file, and include the settings:\n",
    "    ```yaml\n",
    "    model: BPR\n",
    "    dataset: ml-100k\n",
    "    learning_rate: 0.01\n",
    "    ```\n",
    "  * Execute the recommendation pipeline using the specified configuration:\n",
    "    ```python\n",
    "    run_hopwise(config_file_list=['config.yaml'])\n",
    "    ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrXw2suyA10Z"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0Fng62qA10Z",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2Ô∏è‚É£ Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bppqb8KVyD98"
   },
   "source": [
    "`dataset = create_dataset(config)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7ZRQ7xpyD98"
   },
   "source": [
    "<div style=\"background-color:#f0f4f8; border-left: 5px solid #4a90e2; padding:15px; margin:10px 0; border-radius:8px;\">\n",
    "  <p><b>Dataset Module:</b><br><br>\n",
    "   is responsible for loading data and processing it into a format suitable for recommendation tasks. Hopwise supports various data types, including interaction data, knowledge graphs, and contextual information.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8XDmqrsA10Z"
   },
   "source": [
    "After configuring our experiment, the next step is creating the dataset. This involves:\n",
    "\n",
    "1. Loading raw data files\n",
    "2. Preprocessing and filtering data\n",
    "3. Creating internal data structures for efficient access\n",
    "\n",
    "These steps are performed as soon as the need dataset class is initialized. The directive in the quick start example:\n",
    "```python\n",
    "dataset = create_dataset(config)\n",
    "```\n",
    "Depending on the dataset and model type, specific classes will be imported to ensure proper processing of the dataset. For instance, BPR model needs `hopwise.data.dataset.Dataset`, KGAT model needs `hopwise.data.dataset.KnowledgeBasedDataset`.\n",
    "\n",
    "Let's see which information will be provided by the created dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqqYxPBRLg6Z"
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Import necessary libraries\n",
    "# --------------------------------------------\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from hopwise.config import Config\n",
    "from hopwise.data import create_dataset\n",
    "from hopwise.data.dataset import KnowledgeBasedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdOBZmHGLg6a"
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Specify the model and dataset\n",
    "# --------------------------------------------\n",
    "model_name = \"KGAT\"  # A classic recommendation model\n",
    "dataset_name = \"ml-100k\"  # MovieLens 100K dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OO9XzkfGLg6a"
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Define the configuration\n",
    "# --------------------------------------------\n",
    "\n",
    "\n",
    "# Example YAML configuration content\n",
    "yaml_file_content = \"\"\"\n",
    "epochs: 1                     # Number of training epochs (use more for full training)\n",
    "learning_rate: 0.01           # Learning rate for optimization\n",
    "embedding_size: 64            # Size of latent embeddings for users/items\n",
    "train_batch_size: 2048        # Batch size during training\n",
    "eval_batch_size: 8192         # Batch size during evaluation\n",
    "stopping_step: 5              # Early stopping patience (stop if no improvement after 5 validations)\n",
    "\n",
    "load_col:                     # Specify which columns to load from dataset files\n",
    "  inter: [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]    # Interaction data: who rated what and when\n",
    "  item: [\"item_id\", \"movie_title\"]                        # Item data: ID and movie title\n",
    "\n",
    "data_path: /content/drive/MyDrive/XAIKGRLGM/hands-on-session/data/dataset/      # Path to input dataset\n",
    "checkpoint_dir: /content/drive/MyDrive/XAIKGRLGM/hands-on-session/data/checkpoint/  # Where to save model checkpoints\n",
    "\n",
    "metrics:                     # Metrics used for evaluation\n",
    "  - Recall                   # Recall measures hit rate in top-k recommendations\n",
    "  - NDCG                     # NDCG considers the ranking of relevant items\n",
    "\n",
    "valid_metric: Recall@10      # Metric used for validation and early stopping (Recall at 10)\n",
    "topk: [5, 10, 20]            # Top-k values for evaluation metrics\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Create a temporary YAML file to simulate the config file\n",
    "# In a real-world scenario, you would have this file saved on disk\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", encoding=\"utf-8\", suffix=\".yaml\", delete=False) as temp_file:\n",
    "    temp_file.write(yaml_file_content)\n",
    "    temp_file.flush()\n",
    "    temp_file_path = temp_file.name\n",
    "\n",
    "# Optional: config file list for custom settings\n",
    "config_file_list = [temp_file_path]\n",
    "\n",
    "\n",
    "# Create the configuration object\n",
    "config = Config(\n",
    "    model=model_name,\n",
    "    dataset=dataset_name,\n",
    "    config_file_list=config_file_list\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pe8g10wrLg6a"
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# Load the dataset\n",
    "# --------------------------------------------\n",
    "\n",
    "# Loading the dataset using the defined configuration\n",
    "dataset = create_dataset(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-We_Tl7Lg6a"
   },
   "source": [
    "Let's see the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zwamRjvuA10Z",
    "outputId": "9bafffc5-1651-4fab-f292-ac2cc4411328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  üìä Dataset: ml-100k\n",
      "Number of users: 944\n",
      "Number of items: 1683\n",
      "Number of interactions: 97554\n",
      "\n",
      " üåêKnowledge Graph:\n",
      "Number of entities: 34713\n",
      "Number of relations: 26\n",
      "Number of KG triplets: 91631\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --------------------------------------------\n",
    "# Display Dataset & KG statistics\n",
    "# --------------------------------------------\n",
    "\n",
    "\n",
    "# Display dataset statistics\n",
    "print(f\"\\n\\n  üìä Dataset: {dataset.dataset_name}\")\n",
    "print(f\"Number of users: {dataset.user_num}\")\n",
    "print(f\"Number of items: {dataset.item_num}\")\n",
    "print(f\"Number of interactions: {dataset.inter_num}\")\n",
    "\n",
    "\n",
    "\n",
    "# For knowledge graph datasets, show additional information\n",
    "if isinstance(dataset, KnowledgeBasedDataset):\n",
    "    print(\"\\n üåêKnowledge Graph:\")\n",
    "    print(f\"Number of entities: {dataset.entity_num}\")\n",
    "    print(f\"Number of relations: {dataset.relation_num}\")\n",
    "    print(f\"Number of KG triplets: {len(dataset.kg_feat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI_a4AYxA10Z"
   },
   "source": [
    "**üîÑ ID Mapping in Hopwise**\n",
    "\n",
    "As part of preprocessing, **Hopwise maps the original IDs** (called _tokens_) to a new set of **internal IDs** ranging from `1` to `N`.  \n",
    "This remapping simplifies algorithm design by **reserving `0` as a special padding ID**.\n",
    "\n",
    "Padding is commonly used in various models to handle sequences of **variable length**, ensuring consistent input shapes.\n",
    "\n",
    "To support this mechanism, Hopwise provides **conversion functions** to map between tokens and internal IDs ‚Äî **in both directions**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xk9O41PsA10a",
    "outputId": "3fcda018-6bd0-40ac-cf6a-726001d749ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of user original IDs to internal IDs: ['[PAD]', '196', '186', '22', '244', '166', '298', '115', '253', '305', '6', '62', '286', '200', '210', '224', '303', '122', '194', '291', '234', '119', '167', '299', '308', '95', '38', '102', '63', '160', '50', '301', '225', '290', '97', '157', '181', '278', '276', '7', '10', '284', '201', '287', '246', '242', '249', '99', '178', '251', '81', '260', '25', '59', '72', '87', '42', '292', '20', '13', '138', '60', '57', '223', '189', '243', '92', '241', '254', '293', '127', '222', '267', '11', '8', '162', '279', '145', '28', '135', '32', '90', '216', '250', '271', '265', '198', '168', '110', '58', '237', '94', '128', '44', '264', '41', '82', '262', '174', '43', '84', '269', '259', '85', '213', '121', '49', '68', '172', '19', '268', '5', '80', '66', '18', '26', '130', '256', '1', '56', '15', '207', '232', '52', '161', '148', '125', '83', '272', '151', '54', '16', '294', '229', '36', '70', '14', '295', '233', '214', '192', '100', '307', '297', '193', '113', '275', '219', '218', '123', '158', '302', '23', '296', '33', '154', '77', '270', '187', '170', '101', '184', '112', '133', '215', '69', '104', '240', '144', '191', '61', '142', '177', '203', '21', '197', '134', '180', '236', '263', '109', '64', '114', '239', '117', '65', '137', '257', '111', '91', '285', '96', '116', '73', '221', '235', '164', '281', '182', '129', '45', '131', '230', '126', '231', '280', '288', '152', '217', '79', '75', '245', '282', '118', '283', '171', '107', '226', '306', '173', '185', '150', '274', '188', '48', '311', '165', '208', '2', '205', '248', '93', '159', '146', '29', '156', '37', '141', '195', '108', '47', '255', '89', '140', '190', '24', '17', '313', '53', '124', '149', '176', '106', '78', '312', '175', '153', '220', '143', '202', '277', '206', '76', '314', '136', '179', '4', '304', '3', '227', '199', '252', '212', '310', '35', '147', '105', '34', '71', '51', '204', '315', '31', '316', '103', '318', '30', '120', '46', '289', '209', '261', '88', '9', '247', '321', '266', '74', '238', '319', '323', '67', '211', '98', '12', '40', '258', '228', '325', '320', '326', '327', '183', '155', '328', '322', '330', '27', '331', '329', '86', '332', '139', '300', '163', '333', '334', '39', '324', '132', '336', '335', '169', '338', '339', '309', '342', '340', '317', '341', '343', '344', '345', '346', '347', '273', '55', '349', '348', '354', '351', '358', '352', '360', '363', '355', '362', '357', '356', '361', '365', '350', '367', '368', '371', '373', '370', '374', '372', '337', '378', '366', '377', '375', '359', '379', '380', '381', '385', '382', '387', '364', '369', '388', '386', '389', '383', '390', '393', '392', '376', '394', '391', '398', '397', '399', '396', '401', '402', '384', '395', '353', '403', '405', '400', '406', '407', '409', '404', '413', '416', '410', '411', '417', '412', '420', '422', '425', '415', '423', '429', '428', '427', '418', '408', '424', '432', '421', '435', '433', '426', '436', '430', '434', '437', '419', '438', '431', '440', '442', '445', '447', '449', '450', '446', '439', '451', '452', '454', '453', '414', '455', '444', '448', '457', '456', '458', '462', '459', '460', '461', '467', '468', '466', '465', '472', '463', '471', '474', '469', '464', '476', '478', '473', '470', '480', '441', '479', '484', '486', '487', '482', '481', '492', '493', '490', '489', '483', '494', '495', '477', '497', '488', '498', '496', '499', '491', '500', '502', '503', '504', '505', '506', '443', '507', '514', '508', '511', '515', '512', '513', '475', '523', '518', '509', '516', '510', '524', '501', '525', '521', '520', '519', '528', '532', '530', '531', '529', '517', '527', '485', '533', '535', '536', '526', '537', '534', '541', '538', '542', '545', '539', '547', '543', '548', '546', '522', '551', '544', '553', '552', '540', '554', '550', '556', '559', '560', '561', '563', '566', '557', '558', '564', '565', '573', '549', '567', '569', '562', '576', '577', '579', '574', '555', '572', '575', '584', '588', '568', '586', '585', '587', '582', '591', '581', '592', '580', '590', '593', '583', '596', '570', '599', '589', '594', '597', '578', '601', '602', '600', '605', '603', '595', '606', '608', '607', '610', '611', '617', '618', '614', '609', '615', '616', '620', '571', '619', '613', '622', '621', '604', '624', '612', '627', '623', '628', '625', '629', '633', '632', '631', '634', '639', '630', '642', '637', '640', '626', '643', '638', '635', '644', '636', '645', '648', '598', '647', '650', '651', '654', '653', '655', '649', '658', '656', '660', '659', '646', '663', '664', '657', '665', '666', '661', '662', '667', '641', '668', '673', '671', '669', '676', '674', '677', '682', '679', '684', '685', '683', '691', '672', '692', '690', '689', '686', '693', '652', '688', '697', '698', '670', '694', '680', '705', '701', '699', '704', '707', '700', '687', '695', '675', '708', '709', '711', '710', '712', '715', '713', '716', '681', '678', '719', '702', '721', '714', '717', '718', '696', '722', '724', '727', '725', '706', '720', '729', '726', '728', '703', '738', '736', '734', '730', '743', '742', '737', '733', '745', '740', '735', '747', '723', '739', '749', '748', '746', '731', '750', '741', '751', '756', '757', '752', '758', '732', '762', '744', '754', '753', '763', '764', '767', '769', '755', '771', '768', '773', '765', '772', '766', '774', '760', '761', '777', '759', '776', '780', '779', '778', '782', '786', '784', '770', '788', '789', '790', '787', '783', '785', '794', '781', '795', '793', '796', '798', '791', '802', '800', '804', '803', '775', '792', '799', '805', '806', '807', '797', '801', '809', '815', '817', '821', '818', '814', '812', '823', '825', '827', '829', '811', '830', '826', '831', '819', '828', '808', '835', '833', '836', '816', '838', '839', '840', '832', '810', '844', '843', '834', '846', '837', '813', '842', '847', '848', '822', '852', '851', '849', '854', '850', '858', '853', '855', '824', '845', '841', '859', '862', '856', '820', '863', '860', '857', '864', '865', '868', '867', '861', '870', '871', '876', '872', '875', '866', '877', '873', '880', '878', '869', '881', '879', '883', '882', '884', '886', '885', '889', '874', '892', '890', '893', '887', '891', '894', '896', '897', '901', '899', '903', '904', '907', '905', '902', '898', '895', '906', '900', '908', '916', '911', '912', '914', '918', '919', '921', '910', '913', '915', '922', '923', '928', '927', '924', '929', '931', '917', '932', '909', '934', '933', '935', '938', '940', '888', '925', '942', '937', '926', '943', '939', '936', '930', '920', '941']\n",
      "\n",
      "Mapping of user internal IDs to original IDs: {np.str_('[PAD]'): 0, np.str_('196'): 1, np.str_('186'): 2, np.str_('22'): 3, np.str_('244'): 4, np.str_('166'): 5, np.str_('298'): 6, np.str_('115'): 7, np.str_('253'): 8, np.str_('305'): 9, np.str_('6'): 10, np.str_('62'): 11, np.str_('286'): 12, np.str_('200'): 13, np.str_('210'): 14, np.str_('224'): 15, np.str_('303'): 16, np.str_('122'): 17, np.str_('194'): 18, np.str_('291'): 19, np.str_('234'): 20, np.str_('119'): 21, np.str_('167'): 22, np.str_('299'): 23, np.str_('308'): 24, np.str_('95'): 25, np.str_('38'): 26, np.str_('102'): 27, np.str_('63'): 28, np.str_('160'): 29, np.str_('50'): 30, np.str_('301'): 31, np.str_('225'): 32, np.str_('290'): 33, np.str_('97'): 34, np.str_('157'): 35, np.str_('181'): 36, np.str_('278'): 37, np.str_('276'): 38, np.str_('7'): 39, np.str_('10'): 40, np.str_('284'): 41, np.str_('201'): 42, np.str_('287'): 43, np.str_('246'): 44, np.str_('242'): 45, np.str_('249'): 46, np.str_('99'): 47, np.str_('178'): 48, np.str_('251'): 49, np.str_('81'): 50, np.str_('260'): 51, np.str_('25'): 52, np.str_('59'): 53, np.str_('72'): 54, np.str_('87'): 55, np.str_('42'): 56, np.str_('292'): 57, np.str_('20'): 58, np.str_('13'): 59, np.str_('138'): 60, np.str_('60'): 61, np.str_('57'): 62, np.str_('223'): 63, np.str_('189'): 64, np.str_('243'): 65, np.str_('92'): 66, np.str_('241'): 67, np.str_('254'): 68, np.str_('293'): 69, np.str_('127'): 70, np.str_('222'): 71, np.str_('267'): 72, np.str_('11'): 73, np.str_('8'): 74, np.str_('162'): 75, np.str_('279'): 76, np.str_('145'): 77, np.str_('28'): 78, np.str_('135'): 79, np.str_('32'): 80, np.str_('90'): 81, np.str_('216'): 82, np.str_('250'): 83, np.str_('271'): 84, np.str_('265'): 85, np.str_('198'): 86, np.str_('168'): 87, np.str_('110'): 88, np.str_('58'): 89, np.str_('237'): 90, np.str_('94'): 91, np.str_('128'): 92, np.str_('44'): 93, np.str_('264'): 94, np.str_('41'): 95, np.str_('82'): 96, np.str_('262'): 97, np.str_('174'): 98, np.str_('43'): 99, np.str_('84'): 100, np.str_('269'): 101, np.str_('259'): 102, np.str_('85'): 103, np.str_('213'): 104, np.str_('121'): 105, np.str_('49'): 106, np.str_('68'): 107, np.str_('172'): 108, np.str_('19'): 109, np.str_('268'): 110, np.str_('5'): 111, np.str_('80'): 112, np.str_('66'): 113, np.str_('18'): 114, np.str_('26'): 115, np.str_('130'): 116, np.str_('256'): 117, np.str_('1'): 118, np.str_('56'): 119, np.str_('15'): 120, np.str_('207'): 121, np.str_('232'): 122, np.str_('52'): 123, np.str_('161'): 124, np.str_('148'): 125, np.str_('125'): 126, np.str_('83'): 127, np.str_('272'): 128, np.str_('151'): 129, np.str_('54'): 130, np.str_('16'): 131, np.str_('294'): 132, np.str_('229'): 133, np.str_('36'): 134, np.str_('70'): 135, np.str_('14'): 136, np.str_('295'): 137, np.str_('233'): 138, np.str_('214'): 139, np.str_('192'): 140, np.str_('100'): 141, np.str_('307'): 142, np.str_('297'): 143, np.str_('193'): 144, np.str_('113'): 145, np.str_('275'): 146, np.str_('219'): 147, np.str_('218'): 148, np.str_('123'): 149, np.str_('158'): 150, np.str_('302'): 151, np.str_('23'): 152, np.str_('296'): 153, np.str_('33'): 154, np.str_('154'): 155, np.str_('77'): 156, np.str_('270'): 157, np.str_('187'): 158, np.str_('170'): 159, np.str_('101'): 160, np.str_('184'): 161, np.str_('112'): 162, np.str_('133'): 163, np.str_('215'): 164, np.str_('69'): 165, np.str_('104'): 166, np.str_('240'): 167, np.str_('144'): 168, np.str_('191'): 169, np.str_('61'): 170, np.str_('142'): 171, np.str_('177'): 172, np.str_('203'): 173, np.str_('21'): 174, np.str_('197'): 175, np.str_('134'): 176, np.str_('180'): 177, np.str_('236'): 178, np.str_('263'): 179, np.str_('109'): 180, np.str_('64'): 181, np.str_('114'): 182, np.str_('239'): 183, np.str_('117'): 184, np.str_('65'): 185, np.str_('137'): 186, np.str_('257'): 187, np.str_('111'): 188, np.str_('91'): 189, np.str_('285'): 190, np.str_('96'): 191, np.str_('116'): 192, np.str_('73'): 193, np.str_('221'): 194, np.str_('235'): 195, np.str_('164'): 196, np.str_('281'): 197, np.str_('182'): 198, np.str_('129'): 199, np.str_('45'): 200, np.str_('131'): 201, np.str_('230'): 202, np.str_('126'): 203, np.str_('231'): 204, np.str_('280'): 205, np.str_('288'): 206, np.str_('152'): 207, np.str_('217'): 208, np.str_('79'): 209, np.str_('75'): 210, np.str_('245'): 211, np.str_('282'): 212, np.str_('118'): 213, np.str_('283'): 214, np.str_('171'): 215, np.str_('107'): 216, np.str_('226'): 217, np.str_('306'): 218, np.str_('173'): 219, np.str_('185'): 220, np.str_('150'): 221, np.str_('274'): 222, np.str_('188'): 223, np.str_('48'): 224, np.str_('311'): 225, np.str_('165'): 226, np.str_('208'): 227, np.str_('2'): 228, np.str_('205'): 229, np.str_('248'): 230, np.str_('93'): 231, np.str_('159'): 232, np.str_('146'): 233, np.str_('29'): 234, np.str_('156'): 235, np.str_('37'): 236, np.str_('141'): 237, np.str_('195'): 238, np.str_('108'): 239, np.str_('47'): 240, np.str_('255'): 241, np.str_('89'): 242, np.str_('140'): 243, np.str_('190'): 244, np.str_('24'): 245, np.str_('17'): 246, np.str_('313'): 247, np.str_('53'): 248, np.str_('124'): 249, np.str_('149'): 250, np.str_('176'): 251, np.str_('106'): 252, np.str_('78'): 253, np.str_('312'): 254, np.str_('175'): 255, np.str_('153'): 256, np.str_('220'): 257, np.str_('143'): 258, np.str_('202'): 259, np.str_('277'): 260, np.str_('206'): 261, np.str_('76'): 262, np.str_('314'): 263, np.str_('136'): 264, np.str_('179'): 265, np.str_('4'): 266, np.str_('304'): 267, np.str_('3'): 268, np.str_('227'): 269, np.str_('199'): 270, np.str_('252'): 271, np.str_('212'): 272, np.str_('310'): 273, np.str_('35'): 274, np.str_('147'): 275, np.str_('105'): 276, np.str_('34'): 277, np.str_('71'): 278, np.str_('51'): 279, np.str_('204'): 280, np.str_('315'): 281, np.str_('31'): 282, np.str_('316'): 283, np.str_('103'): 284, np.str_('318'): 285, np.str_('30'): 286, np.str_('120'): 287, np.str_('46'): 288, np.str_('289'): 289, np.str_('209'): 290, np.str_('261'): 291, np.str_('88'): 292, np.str_('9'): 293, np.str_('247'): 294, np.str_('321'): 295, np.str_('266'): 296, np.str_('74'): 297, np.str_('238'): 298, np.str_('319'): 299, np.str_('323'): 300, np.str_('67'): 301, np.str_('211'): 302, np.str_('98'): 303, np.str_('12'): 304, np.str_('40'): 305, np.str_('258'): 306, np.str_('228'): 307, np.str_('325'): 308, np.str_('320'): 309, np.str_('326'): 310, np.str_('327'): 311, np.str_('183'): 312, np.str_('155'): 313, np.str_('328'): 314, np.str_('322'): 315, np.str_('330'): 316, np.str_('27'): 317, np.str_('331'): 318, np.str_('329'): 319, np.str_('86'): 320, np.str_('332'): 321, np.str_('139'): 322, np.str_('300'): 323, np.str_('163'): 324, np.str_('333'): 325, np.str_('334'): 326, np.str_('39'): 327, np.str_('324'): 328, np.str_('132'): 329, np.str_('336'): 330, np.str_('335'): 331, np.str_('169'): 332, np.str_('338'): 333, np.str_('339'): 334, np.str_('309'): 335, np.str_('342'): 336, np.str_('340'): 337, np.str_('317'): 338, np.str_('341'): 339, np.str_('343'): 340, np.str_('344'): 341, np.str_('345'): 342, np.str_('346'): 343, np.str_('347'): 344, np.str_('273'): 345, np.str_('55'): 346, np.str_('349'): 347, np.str_('348'): 348, np.str_('354'): 349, np.str_('351'): 350, np.str_('358'): 351, np.str_('352'): 352, np.str_('360'): 353, np.str_('363'): 354, np.str_('355'): 355, np.str_('362'): 356, np.str_('357'): 357, np.str_('356'): 358, np.str_('361'): 359, np.str_('365'): 360, np.str_('350'): 361, np.str_('367'): 362, np.str_('368'): 363, np.str_('371'): 364, np.str_('373'): 365, np.str_('370'): 366, np.str_('374'): 367, np.str_('372'): 368, np.str_('337'): 369, np.str_('378'): 370, np.str_('366'): 371, np.str_('377'): 372, np.str_('375'): 373, np.str_('359'): 374, np.str_('379'): 375, np.str_('380'): 376, np.str_('381'): 377, np.str_('385'): 378, np.str_('382'): 379, np.str_('387'): 380, np.str_('364'): 381, np.str_('369'): 382, np.str_('388'): 383, np.str_('386'): 384, np.str_('389'): 385, np.str_('383'): 386, np.str_('390'): 387, np.str_('393'): 388, np.str_('392'): 389, np.str_('376'): 390, np.str_('394'): 391, np.str_('391'): 392, np.str_('398'): 393, np.str_('397'): 394, np.str_('399'): 395, np.str_('396'): 396, np.str_('401'): 397, np.str_('402'): 398, np.str_('384'): 399, np.str_('395'): 400, np.str_('353'): 401, np.str_('403'): 402, np.str_('405'): 403, np.str_('400'): 404, np.str_('406'): 405, np.str_('407'): 406, np.str_('409'): 407, np.str_('404'): 408, np.str_('413'): 409, np.str_('416'): 410, np.str_('410'): 411, np.str_('411'): 412, np.str_('417'): 413, np.str_('412'): 414, np.str_('420'): 415, np.str_('422'): 416, np.str_('425'): 417, np.str_('415'): 418, np.str_('423'): 419, np.str_('429'): 420, np.str_('428'): 421, np.str_('427'): 422, np.str_('418'): 423, np.str_('408'): 424, np.str_('424'): 425, np.str_('432'): 426, np.str_('421'): 427, np.str_('435'): 428, np.str_('433'): 429, np.str_('426'): 430, np.str_('436'): 431, np.str_('430'): 432, np.str_('434'): 433, np.str_('437'): 434, np.str_('419'): 435, np.str_('438'): 436, np.str_('431'): 437, np.str_('440'): 438, np.str_('442'): 439, np.str_('445'): 440, np.str_('447'): 441, np.str_('449'): 442, np.str_('450'): 443, np.str_('446'): 444, np.str_('439'): 445, np.str_('451'): 446, np.str_('452'): 447, np.str_('454'): 448, np.str_('453'): 449, np.str_('414'): 450, np.str_('455'): 451, np.str_('444'): 452, np.str_('448'): 453, np.str_('457'): 454, np.str_('456'): 455, np.str_('458'): 456, np.str_('462'): 457, np.str_('459'): 458, np.str_('460'): 459, np.str_('461'): 460, np.str_('467'): 461, np.str_('468'): 462, np.str_('466'): 463, np.str_('465'): 464, np.str_('472'): 465, np.str_('463'): 466, np.str_('471'): 467, np.str_('474'): 468, np.str_('469'): 469, np.str_('464'): 470, np.str_('476'): 471, np.str_('478'): 472, np.str_('473'): 473, np.str_('470'): 474, np.str_('480'): 475, np.str_('441'): 476, np.str_('479'): 477, np.str_('484'): 478, np.str_('486'): 479, np.str_('487'): 480, np.str_('482'): 481, np.str_('481'): 482, np.str_('492'): 483, np.str_('493'): 484, np.str_('490'): 485, np.str_('489'): 486, np.str_('483'): 487, np.str_('494'): 488, np.str_('495'): 489, np.str_('477'): 490, np.str_('497'): 491, np.str_('488'): 492, np.str_('498'): 493, np.str_('496'): 494, np.str_('499'): 495, np.str_('491'): 496, np.str_('500'): 497, np.str_('502'): 498, np.str_('503'): 499, np.str_('504'): 500, np.str_('505'): 501, np.str_('506'): 502, np.str_('443'): 503, np.str_('507'): 504, np.str_('514'): 505, np.str_('508'): 506, np.str_('511'): 507, np.str_('515'): 508, np.str_('512'): 509, np.str_('513'): 510, np.str_('475'): 511, np.str_('523'): 512, np.str_('518'): 513, np.str_('509'): 514, np.str_('516'): 515, np.str_('510'): 516, np.str_('524'): 517, np.str_('501'): 518, np.str_('525'): 519, np.str_('521'): 520, np.str_('520'): 521, np.str_('519'): 522, np.str_('528'): 523, np.str_('532'): 524, np.str_('530'): 525, np.str_('531'): 526, np.str_('529'): 527, np.str_('517'): 528, np.str_('527'): 529, np.str_('485'): 530, np.str_('533'): 531, np.str_('535'): 532, np.str_('536'): 533, np.str_('526'): 534, np.str_('537'): 535, np.str_('534'): 536, np.str_('541'): 537, np.str_('538'): 538, np.str_('542'): 539, np.str_('545'): 540, np.str_('539'): 541, np.str_('547'): 542, np.str_('543'): 543, np.str_('548'): 544, np.str_('546'): 545, np.str_('522'): 546, np.str_('551'): 547, np.str_('544'): 548, np.str_('553'): 549, np.str_('552'): 550, np.str_('540'): 551, np.str_('554'): 552, np.str_('550'): 553, np.str_('556'): 554, np.str_('559'): 555, np.str_('560'): 556, np.str_('561'): 557, np.str_('563'): 558, np.str_('566'): 559, np.str_('557'): 560, np.str_('558'): 561, np.str_('564'): 562, np.str_('565'): 563, np.str_('573'): 564, np.str_('549'): 565, np.str_('567'): 566, np.str_('569'): 567, np.str_('562'): 568, np.str_('576'): 569, np.str_('577'): 570, np.str_('579'): 571, np.str_('574'): 572, np.str_('555'): 573, np.str_('572'): 574, np.str_('575'): 575, np.str_('584'): 576, np.str_('588'): 577, np.str_('568'): 578, np.str_('586'): 579, np.str_('585'): 580, np.str_('587'): 581, np.str_('582'): 582, np.str_('591'): 583, np.str_('581'): 584, np.str_('592'): 585, np.str_('580'): 586, np.str_('590'): 587, np.str_('593'): 588, np.str_('583'): 589, np.str_('596'): 590, np.str_('570'): 591, np.str_('599'): 592, np.str_('589'): 593, np.str_('594'): 594, np.str_('597'): 595, np.str_('578'): 596, np.str_('601'): 597, np.str_('602'): 598, np.str_('600'): 599, np.str_('605'): 600, np.str_('603'): 601, np.str_('595'): 602, np.str_('606'): 603, np.str_('608'): 604, np.str_('607'): 605, np.str_('610'): 606, np.str_('611'): 607, np.str_('617'): 608, np.str_('618'): 609, np.str_('614'): 610, np.str_('609'): 611, np.str_('615'): 612, np.str_('616'): 613, np.str_('620'): 614, np.str_('571'): 615, np.str_('619'): 616, np.str_('613'): 617, np.str_('622'): 618, np.str_('621'): 619, np.str_('604'): 620, np.str_('624'): 621, np.str_('612'): 622, np.str_('627'): 623, np.str_('623'): 624, np.str_('628'): 625, np.str_('625'): 626, np.str_('629'): 627, np.str_('633'): 628, np.str_('632'): 629, np.str_('631'): 630, np.str_('634'): 631, np.str_('639'): 632, np.str_('630'): 633, np.str_('642'): 634, np.str_('637'): 635, np.str_('640'): 636, np.str_('626'): 637, np.str_('643'): 638, np.str_('638'): 639, np.str_('635'): 640, np.str_('644'): 641, np.str_('636'): 642, np.str_('645'): 643, np.str_('648'): 644, np.str_('598'): 645, np.str_('647'): 646, np.str_('650'): 647, np.str_('651'): 648, np.str_('654'): 649, np.str_('653'): 650, np.str_('655'): 651, np.str_('649'): 652, np.str_('658'): 653, np.str_('656'): 654, np.str_('660'): 655, np.str_('659'): 656, np.str_('646'): 657, np.str_('663'): 658, np.str_('664'): 659, np.str_('657'): 660, np.str_('665'): 661, np.str_('666'): 662, np.str_('661'): 663, np.str_('662'): 664, np.str_('667'): 665, np.str_('641'): 666, np.str_('668'): 667, np.str_('673'): 668, np.str_('671'): 669, np.str_('669'): 670, np.str_('676'): 671, np.str_('674'): 672, np.str_('677'): 673, np.str_('682'): 674, np.str_('679'): 675, np.str_('684'): 676, np.str_('685'): 677, np.str_('683'): 678, np.str_('691'): 679, np.str_('672'): 680, np.str_('692'): 681, np.str_('690'): 682, np.str_('689'): 683, np.str_('686'): 684, np.str_('693'): 685, np.str_('652'): 686, np.str_('688'): 687, np.str_('697'): 688, np.str_('698'): 689, np.str_('670'): 690, np.str_('694'): 691, np.str_('680'): 692, np.str_('705'): 693, np.str_('701'): 694, np.str_('699'): 695, np.str_('704'): 696, np.str_('707'): 697, np.str_('700'): 698, np.str_('687'): 699, np.str_('695'): 700, np.str_('675'): 701, np.str_('708'): 702, np.str_('709'): 703, np.str_('711'): 704, np.str_('710'): 705, np.str_('712'): 706, np.str_('715'): 707, np.str_('713'): 708, np.str_('716'): 709, np.str_('681'): 710, np.str_('678'): 711, np.str_('719'): 712, np.str_('702'): 713, np.str_('721'): 714, np.str_('714'): 715, np.str_('717'): 716, np.str_('718'): 717, np.str_('696'): 718, np.str_('722'): 719, np.str_('724'): 720, np.str_('727'): 721, np.str_('725'): 722, np.str_('706'): 723, np.str_('720'): 724, np.str_('729'): 725, np.str_('726'): 726, np.str_('728'): 727, np.str_('703'): 728, np.str_('738'): 729, np.str_('736'): 730, np.str_('734'): 731, np.str_('730'): 732, np.str_('743'): 733, np.str_('742'): 734, np.str_('737'): 735, np.str_('733'): 736, np.str_('745'): 737, np.str_('740'): 738, np.str_('735'): 739, np.str_('747'): 740, np.str_('723'): 741, np.str_('739'): 742, np.str_('749'): 743, np.str_('748'): 744, np.str_('746'): 745, np.str_('731'): 746, np.str_('750'): 747, np.str_('741'): 748, np.str_('751'): 749, np.str_('756'): 750, np.str_('757'): 751, np.str_('752'): 752, np.str_('758'): 753, np.str_('732'): 754, np.str_('762'): 755, np.str_('744'): 756, np.str_('754'): 757, np.str_('753'): 758, np.str_('763'): 759, np.str_('764'): 760, np.str_('767'): 761, np.str_('769'): 762, np.str_('755'): 763, np.str_('771'): 764, np.str_('768'): 765, np.str_('773'): 766, np.str_('765'): 767, np.str_('772'): 768, np.str_('766'): 769, np.str_('774'): 770, np.str_('760'): 771, np.str_('761'): 772, np.str_('777'): 773, np.str_('759'): 774, np.str_('776'): 775, np.str_('780'): 776, np.str_('779'): 777, np.str_('778'): 778, np.str_('782'): 779, np.str_('786'): 780, np.str_('784'): 781, np.str_('770'): 782, np.str_('788'): 783, np.str_('789'): 784, np.str_('790'): 785, np.str_('787'): 786, np.str_('783'): 787, np.str_('785'): 788, np.str_('794'): 789, np.str_('781'): 790, np.str_('795'): 791, np.str_('793'): 792, np.str_('796'): 793, np.str_('798'): 794, np.str_('791'): 795, np.str_('802'): 796, np.str_('800'): 797, np.str_('804'): 798, np.str_('803'): 799, np.str_('775'): 800, np.str_('792'): 801, np.str_('799'): 802, np.str_('805'): 803, np.str_('806'): 804, np.str_('807'): 805, np.str_('797'): 806, np.str_('801'): 807, np.str_('809'): 808, np.str_('815'): 809, np.str_('817'): 810, np.str_('821'): 811, np.str_('818'): 812, np.str_('814'): 813, np.str_('812'): 814, np.str_('823'): 815, np.str_('825'): 816, np.str_('827'): 817, np.str_('829'): 818, np.str_('811'): 819, np.str_('830'): 820, np.str_('826'): 821, np.str_('831'): 822, np.str_('819'): 823, np.str_('828'): 824, np.str_('808'): 825, np.str_('835'): 826, np.str_('833'): 827, np.str_('836'): 828, np.str_('816'): 829, np.str_('838'): 830, np.str_('839'): 831, np.str_('840'): 832, np.str_('832'): 833, np.str_('810'): 834, np.str_('844'): 835, np.str_('843'): 836, np.str_('834'): 837, np.str_('846'): 838, np.str_('837'): 839, np.str_('813'): 840, np.str_('842'): 841, np.str_('847'): 842, np.str_('848'): 843, np.str_('822'): 844, np.str_('852'): 845, np.str_('851'): 846, np.str_('849'): 847, np.str_('854'): 848, np.str_('850'): 849, np.str_('858'): 850, np.str_('853'): 851, np.str_('855'): 852, np.str_('824'): 853, np.str_('845'): 854, np.str_('841'): 855, np.str_('859'): 856, np.str_('862'): 857, np.str_('856'): 858, np.str_('820'): 859, np.str_('863'): 860, np.str_('860'): 861, np.str_('857'): 862, np.str_('864'): 863, np.str_('865'): 864, np.str_('868'): 865, np.str_('867'): 866, np.str_('861'): 867, np.str_('870'): 868, np.str_('871'): 869, np.str_('876'): 870, np.str_('872'): 871, np.str_('875'): 872, np.str_('866'): 873, np.str_('877'): 874, np.str_('873'): 875, np.str_('880'): 876, np.str_('878'): 877, np.str_('869'): 878, np.str_('881'): 879, np.str_('879'): 880, np.str_('883'): 881, np.str_('882'): 882, np.str_('884'): 883, np.str_('886'): 884, np.str_('885'): 885, np.str_('889'): 886, np.str_('874'): 887, np.str_('892'): 888, np.str_('890'): 889, np.str_('893'): 890, np.str_('887'): 891, np.str_('891'): 892, np.str_('894'): 893, np.str_('896'): 894, np.str_('897'): 895, np.str_('901'): 896, np.str_('899'): 897, np.str_('903'): 898, np.str_('904'): 899, np.str_('907'): 900, np.str_('905'): 901, np.str_('902'): 902, np.str_('898'): 903, np.str_('895'): 904, np.str_('906'): 905, np.str_('900'): 906, np.str_('908'): 907, np.str_('916'): 908, np.str_('911'): 909, np.str_('912'): 910, np.str_('914'): 911, np.str_('918'): 912, np.str_('919'): 913, np.str_('921'): 914, np.str_('910'): 915, np.str_('913'): 916, np.str_('915'): 917, np.str_('922'): 918, np.str_('923'): 919, np.str_('928'): 920, np.str_('927'): 921, np.str_('924'): 922, np.str_('929'): 923, np.str_('931'): 924, np.str_('917'): 925, np.str_('932'): 926, np.str_('909'): 927, np.str_('934'): 928, np.str_('933'): 929, np.str_('935'): 930, np.str_('938'): 931, np.str_('940'): 932, np.str_('888'): 933, np.str_('925'): 934, np.str_('942'): 935, np.str_('937'): 936, np.str_('926'): 937, np.str_('943'): 938, np.str_('939'): 939, np.str_('936'): 940, np.str_('930'): 941, np.str_('920'): 942, np.str_('941'): 943}\n",
      "\n",
      "\n",
      "Example of mapping user IDs:\n",
      "\n",
      "Original ID:   '30'  -->    Internal ID: '50'\n",
      "Internal ID:   '50'  -->    Original ID: '30'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mapping of user original IDs to internal IDs: {dataset.field2id_token[dataset.uid_field].tolist()}\")\n",
    "#print(f\"Mapping of item original IDs to internal IDs: {dataset.field2id_token[dataset.iid_field].tolist()}\")\n",
    "\n",
    "print(f\"\\nMapping of user internal IDs to original IDs: {dataset.field2token_id[dataset.uid_field]}\")\n",
    "#print(f\"Mapping of item internal IDs to original IDs: {dataset.field2token_id[dataset.iid_field]}\")\n",
    "\n",
    "# Example usage of the mapping\n",
    "print(\"\\n\\nExample of mapping user IDs:\")\n",
    "# Assuming user_id is an integer representing the original user ID\n",
    "user_id = 30\n",
    "# Convert original user ID to internal ID\n",
    "orig_user_id = dataset.field2id_token[dataset.uid_field][user_id]\n",
    "\n",
    "# Print the mapping of the original user ID to the internal ID\n",
    "print(f\"\\nOriginal ID:   '{user_id}'  -->    Internal ID: '{orig_user_id}'\")\n",
    "print(f\"Internal ID:   '{orig_user_id}'  -->    Original ID: '{dataset.field2token_id[dataset.uid_field][orig_user_id]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBqGopkOA10a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3Ô∏è‚É£ Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hE6vkBQyD9-"
   },
   "source": [
    "`train_data, valid_data, test_data = data_preparation(config,dataset)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnffxkBUyD9-"
   },
   "source": [
    "<div style=\"background-color:#f0f4f8; border-left: 5px solid #4a90e2; padding:15px; margin:10px 0; border-radius:8px;\">\n",
    "  <p><b>Dataset Preparation:</b><br><br>\n",
    "    Prepare the data for training and evaluating the models by splitting the dataset, creating <em> samplers </em> for negative sampling, and building <em> dataloaders </em> to efficiently feed data into the models.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgz8l9YWA10a"
   },
   "source": [
    "Once we have our dataset, we need to prepare it for training and evaluation. This includes:\n",
    "\n",
    "1. Splitting the data into train/validation/test sets\n",
    "2. Setting up samplers for negative sampling for training\n",
    "3. Masking training interactions for evaluation\n",
    "4. Setting up batches using  dataloaders and auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsxXsd5syD9-"
   },
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\">\n",
    "<b>üìå </b> <b>Remember: What is <em> Negative Sampling </em>? </b> <br>\n",
    "  <p>\n",
    "    In recommender systems, we usually know what users <strong>liked</strong> ‚Äî for example, a movie they watched or rated.\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    But we don‚Äôt know what they <strong>didn‚Äôt like</strong>, because people don‚Äôt usually say what they ignored or skipped.\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    To train a model, we need both positive and negative examples. So we create <em>negative samples</em> by picking random items that the user\n",
    "    <strong>has not interacted with</strong>.\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    These items are used as \"negatives\" during training.\n",
    "  </p>\n",
    "\n",
    "  <p>\n",
    "    This helps the model learn to recommend only the items the user is likely to enjoy ‚Äî and <strong>not</strong> recommend the others.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3MF9NTgyD9-"
   },
   "source": [
    "We‚Äôll now inspect how the dataset is split and how the dataloader is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MY_aasAbA10a",
    "outputId": "3d582a24-07aa-41ad-e673-fff88c50603c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  üì¶ Training DataLoader:\n",
      "  Training batch size: 2048\n",
      "  Evaluation batch size: 4\n",
      "  Number of training batches: 39\n",
      "  Number of validation batches: 236\n",
      "  Number of test batches: 236\n"
     ]
    }
   ],
   "source": [
    "from hopwise.data import KGSampler, KnowledgeBasedDataLoader, create_samplers, data_preparation, get_dataloader\n",
    "\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "# Check if the training data is using a knowledge-based dataloader\n",
    "# (i.e., for models that use a knowledge graph)\n",
    "if isinstance(train_data, KnowledgeBasedDataLoader):\n",
    "    # If true, get the batch size from the internal general_dataloader\n",
    "    train_batch_size = train_data.general_dataloader.batch_size\n",
    "    # Also get the total number of batches from the internal dataloader\n",
    "    len_train_data = len(train_data.general_dataloader)\n",
    "else:\n",
    "    # If it's a regular dataloader, access batch size directly\n",
    "    train_batch_size = train_data.batch_size\n",
    "    # And get the number of batches directly\n",
    "    len_train_data = len(train_data)\n",
    "\n",
    "\n",
    "print(\"\\n\\n  üì¶ Training DataLoader:\")\n",
    "print(f\"  Training batch size: {train_batch_size}\")\n",
    "print(f\"  Evaluation batch size: {test_data.batch_size}\")\n",
    "print(f\"  Number of training batches: {len_train_data}\")\n",
    "print(f\"  Number of validation batches: {len(valid_data)}\")\n",
    "print(f\"  Number of test batches: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soXFJAkPO7zL"
   },
   "source": [
    "The evaluation batch size does not correspond to the one we set in the configuration because of the inherent way recommender system are evaluated.  \n",
    "We need to predict the score for each <user, item> pair and the evaluation batch size that we decide in configuration corresponds to the number of <user, item> pairs.  \n",
    "\n",
    "> So, what is the value returned by the print above?\n",
    "\n",
    "For a fixed user _u_, we need to predict the score between _u_ and all items. The new value of the evaluation batch size represents the number of users for which the score with all items can be computed, such that the amount of <user, item> pairs is less than the original value in the configuration.  \n",
    "\n",
    "Remind that MovieLens-100k has 943 users and 1682 items.  \n",
    "If we set `eval_batch_size = 8192`, we can only compute the prediction scores for up to 4 users.\n",
    "\n",
    "Selecting 5 users would result in 5 * 1682 = 8410 <user, item> pairs, which is larger than the `eval_batch_size` we set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\">\n",
    "  <b>üìå </b> <b>What does the <code>batch_size</code> really mean?</b> <br>\n",
    "  <p>\n",
    "    The <code>eval_batch_size</code> in the config doesn't mean number of users. It means maximum number of <code>&lt;user,item&gt;</code> pairs per batch.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZs06Sp3A10a"
   },
   "source": [
    "## 4Ô∏è‚É£ Model Inizialitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eJuZfziyD9-"
   },
   "source": [
    "In this step, Hopwise selects and builds the model specified in the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LeU4dcUZLg6c",
    "outputId": "7e42edac-a05d-4ade-f6c0-168d46bdecf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/hopwise/model/knowledge_aware_recommender/kgat.py:135: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1).flatten()\n",
      "/usr/local/lib/python3.11/dist-packages/hopwise/model/knowledge_aware_recommender/kgat.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  indices = torch.LongTensor([final_adj_matrix.row, final_adj_matrix.col])\n",
      "/usr/local/lib/python3.11/dist-packages/hopwise/model/knowledge_aware_recommender/kgat.py:144: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:644.)\n",
      "  adj_matrix_tensor = torch.sparse.FloatTensor(indices, values, self.matrix_size)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KGAT(\n",
       "  (user_embedding): Embedding(944, 64)\n",
       "  (entity_embedding): Embedding(34713, 64)\n",
       "  (relation_embedding): Embedding(26, 64)\n",
       "  (trans_w): Embedding(26, 4096)\n",
       "  (aggregator_layers): ModuleList(\n",
       "    (0): Aggregator(\n",
       "      (message_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (W1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (W2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (activation): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (tanh): Tanh()\n",
       "  (mf_loss): BPRLoss()\n",
       "  (reg_loss): EmbLoss()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hopwise.utils import get_model\n",
    "\n",
    "model = get_model(config[\"model\"])(config, train_data.dataset).to(config[\"device\"])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfKm_98wO7zM"
   },
   "source": [
    "Models in Hopwise are PyTorch Modules, enabling strong independence from the rest of the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9tgCAgwEO7zM",
    "outputId": "07440a49-ac94-4c9d-c3d7-055b469fb705"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  üì¶ Model:\n",
      "  Model name: KGAT\n",
      "  Model parameters: <generator object Module.parameters at 0x7e91e066e180>\n",
      "  Model state: OrderedDict([('user_embedding.weight', tensor([[ 0.0013,  0.0673, -0.0327,  ...,  0.0147,  0.0554, -0.0553],\n",
      "        [-0.0768, -0.0809,  0.0495,  ...,  0.0072,  0.0053,  0.0589],\n",
      "        [-0.0683,  0.0373,  0.0707,  ..., -0.0598, -0.0191,  0.0719],\n",
      "        ...,\n",
      "        [ 0.0052,  0.0282, -0.0067,  ..., -0.0116,  0.0348, -0.0223],\n",
      "        [ 0.0199, -0.0180, -0.0350,  ..., -0.0206, -0.1051,  0.0087],\n",
      "        [ 0.0555,  0.1143,  0.0100,  ...,  0.0231, -0.0745, -0.0534]])), ('entity_embedding.weight', tensor([[-0.0058,  0.0156,  0.0077,  ...,  0.0007, -0.0063,  0.0029],\n",
      "        [ 0.0021, -0.0169,  0.0020,  ...,  0.0037,  0.0057,  0.0014],\n",
      "        [ 0.0102, -0.0098, -0.0103,  ...,  0.0065,  0.0221,  0.0062],\n",
      "        ...,\n",
      "        [-0.0074,  0.0039,  0.0113,  ...,  0.0054,  0.0021,  0.0071],\n",
      "        [ 0.0129, -0.0036,  0.0149,  ..., -0.0037, -0.0039, -0.0005],\n",
      "        [ 0.0027, -0.0057,  0.0003,  ..., -0.0157, -0.0003,  0.0142]])), ('relation_embedding.weight', tensor([[ 0.2099,  0.2732,  0.0416,  ...,  0.0485, -0.0118,  0.0190],\n",
      "        [-0.3182, -0.0017,  0.2344,  ..., -0.0350, -0.0033,  0.0906],\n",
      "        [ 0.0451,  0.0833,  0.0106,  ...,  0.0524, -0.1168, -0.1256],\n",
      "        ...,\n",
      "        [ 0.0132, -0.0360, -0.2701,  ...,  0.0494,  0.1134, -0.0092],\n",
      "        [-0.0990,  0.0132,  0.1216,  ..., -0.0915, -0.2202, -0.0489],\n",
      "        [-0.0245, -0.0400, -0.2078,  ..., -0.1074, -0.0985,  0.2152]])), ('trans_w.weight', tensor([[-0.0137, -0.0086, -0.0128,  ..., -0.0107, -0.0522, -0.0055],\n",
      "        [-0.0034, -0.0086, -0.0072,  ...,  0.0194, -0.0267,  0.0024],\n",
      "        [ 0.0175,  0.0268, -0.0353,  ..., -0.0140,  0.0087,  0.0099],\n",
      "        ...,\n",
      "        [-0.0330,  0.0251,  0.0173,  ...,  0.0145, -0.0400,  0.0152],\n",
      "        [ 0.0141, -0.0486, -0.0088,  ..., -0.0159, -0.0079,  0.0109],\n",
      "        [ 0.0189, -0.0053, -0.0263,  ..., -0.0152, -0.0188, -0.0188]])), ('aggregator_layers.0.W1.weight', tensor([[-1.4239e-02,  1.5172e-01, -6.9080e-02,  ..., -1.8797e-01,\n",
      "          2.0013e-02, -1.2191e-01],\n",
      "        [-2.2936e-03, -6.1471e-02,  1.3715e-01,  ...,  1.2708e-01,\n",
      "          4.2788e-02,  1.9633e-01],\n",
      "        [-4.3324e-02,  1.4844e-01,  1.4504e-01,  ..., -5.6394e-02,\n",
      "          3.3051e-04,  8.6544e-02],\n",
      "        ...,\n",
      "        [ 1.8961e-01, -2.3634e-01,  2.1365e-01,  ..., -1.4305e-01,\n",
      "         -4.1955e-02, -2.6143e-01],\n",
      "        [-3.5503e-02,  1.9106e-02, -1.3742e-01,  ..., -1.7887e-04,\n",
      "          1.2262e-01,  1.9955e-01],\n",
      "        [-6.0431e-02, -5.0666e-02, -1.2251e-01,  ..., -4.7732e-02,\n",
      "         -7.1202e-02,  1.4683e-01]])), ('aggregator_layers.0.W1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('aggregator_layers.0.W2.weight', tensor([[-0.0389, -0.0891,  0.0096,  ...,  0.0522, -0.0252, -0.0563],\n",
      "        [-0.0838, -0.3666, -0.0983,  ..., -0.2962,  0.1403,  0.1357],\n",
      "        [ 0.0193, -0.1065,  0.1783,  ...,  0.0282,  0.0486,  0.0927],\n",
      "        ...,\n",
      "        [-0.0967,  0.0731,  0.2332,  ...,  0.0346, -0.1863, -0.0670],\n",
      "        [ 0.2268,  0.2274, -0.0651,  ..., -0.1464,  0.1145, -0.0845],\n",
      "        [-0.0034, -0.0530, -0.0568,  ..., -0.1950,  0.0237,  0.1040]])), ('aggregator_layers.0.W2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])\n",
      "  Model device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n  üì¶ Model:\")\n",
    "print(f\"  Model name: {model.__class__.__name__}\")\n",
    "print(f\"  Model parameters: {model.parameters()}\")\n",
    "print(f\"  Model state: {model.state_dict()}\")\n",
    "print(f\"  Model device: {model.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4rNhh12O7zM"
   },
   "source": [
    "Most of the models include the following functions:\n",
    "- `forward`: Processes input data through the model's core architecture. In BPR, for example, it retrieves user and item embeddings and returns them for further processing. This function defines how data flows through the model.\n",
    "\n",
    "- `calculate_loss`: Computes the training objective to optimize. For BPR, it calculates the Bayesian Personalized Ranking loss between positive and negative item pairs. This loss guides the model to rank preferred items higher than non-preferred ones.\n",
    "\n",
    "- `predict`: Calculates a recommendation score for a specific user-item pair. In BPR, it computes the dot product between user and item embeddings. This function is used during inference for individual predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pem3JTiJA10a"
   },
   "source": [
    "## 5Ô∏è‚É£ - 6Ô∏è‚É£ : Trainer Setup & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkFa8qVUyD9_"
   },
   "source": [
    "5. `trainer = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])(config, model)`\n",
    "\n",
    "\n",
    "6. `trainer.fit( train_data, valid_data, saved=True, show_progress=config[\"show_progress\"])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZzvUozgO7zM"
   },
   "source": [
    "The training phase includes two main steps:\n",
    "- **Instantiation**: we prepare the Trainer, which internally creates the supporting objects to perform the iterative training process and the models' evaluation\n",
    "- **Fit**: executes the proper training phase, expecting the training data and validation data (optional) to verify the model' generalization ability on the validation set, fundamental to monitor the performance and enable the early stopping functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghahVLGOyD9_"
   },
   "source": [
    "#### **5. Trainer Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CyB6kkDyO7zM",
    "outputId": "5c089629-968c-4200-9de0-765243345682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  üì¶ Trainer:\n",
      "  Trainer name: KGATTrainer\n",
      "  Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      ")\n",
      "  Learning rate: 0.01\n",
      "  Epochs: 1\n",
      "  Model file path: /content/drive/MyDrive/XAIKGRLGM/hands-on-session/data/checkpoint/KGAT-Jul-08-2025_18-39-43.pth\n",
      "  Stopping step: 5\n",
      "  Tensorboard: <torch.utils.tensorboard.writer.SummaryWriter object at 0x7e91e362dc10>\n",
      "  WandbLogger: <hopwise.utils.wandblogger.WandbLogger object at 0x7e91e06611d0>\n"
     ]
    }
   ],
   "source": [
    "from hopwise.utils import get_trainer\n",
    "\n",
    "trainer = get_trainer(config[\"MODEL_TYPE\"], config[\"model\"])(config, model)\n",
    "print(\"\\n\\n  üì¶ Trainer:\")\n",
    "print(f\"  Trainer name: {trainer.__class__.__name__}\")\n",
    "print(f\"  Optimizer: {trainer.optimizer}\")\n",
    "print(f\"  Learning rate: {trainer.learning_rate}\")\n",
    "print(f\"  Epochs: {trainer.epochs}\")\n",
    "print(f\"  Model file path: {trainer.saved_model_file}\")\n",
    "print(f\"  Stopping step: {trainer.stopping_step}\")\n",
    "print(f\"  Tensorboard: {trainer.tensorboard}\")\n",
    "print(f\"  WandbLogger: {trainer.wandblogger}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAEO0LdcyD9_"
   },
   "source": [
    "#### **6. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260,
     "referenced_widgets": [
      "1e302b4ad9534e769b9844fb3617e1e8",
      "0bae7bef979645f287afa6fbec5edab3",
      "45edb2d761e94167a237db542e80534b",
      "4d22c04d257949a39716ada0f26aab11",
      "6c8cf91746cd45029b2b88875136b7c2",
      "93e1f78976534166b5eb54b9e41d0686"
     ]
    },
    "id": "bl6SvpmQjM_F",
    "outputId": "3a690f04-a053-4b3b-f615-77f8dfd3970a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e302b4ad9534e769b9844fb3617e1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/hopwise/trainer/trainer.py:227: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  rich.tqdm(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45edb2d761e94167a237db542e80534b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8cf91746cd45029b2b88875136b7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/hopwise/trainer/trainer.py:565: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  rich.tqdm(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.0837),\n",
       " OrderedDict([('recall@5', np.float64(0.0454)),\n",
       "              ('recall@10', np.float64(0.0837)),\n",
       "              ('recall@20', np.float64(0.1364)),\n",
       "              ('ndcg@5', np.float64(0.0941)),\n",
       "              ('ndcg@10', np.float64(0.0991)),\n",
       "              ('ndcg@20', np.float64(0.1106))]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit( train_data, valid_data, saved=True, show_progress=config[\"show_progress\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7HXxDvuA10a"
   },
   "source": [
    "## 7Ô∏è‚É£ Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVbbbWt1yD9_"
   },
   "source": [
    "`test_result = trainer.evaluate(test_data, load_best_model=True, model_file=None, show_progress=config[\"show_progress\"])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80uKdY3XO7zM"
   },
   "source": [
    "The evaluation phase uses again the Trainer to extract the prediction scores from the users in the test data and consequently compute the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxwjcJQtO7zM",
    "outputId": "0b609445-8952-400e-937a-1c246959a5c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluation step: 1\n",
      "  Evaluation metric: recall@10\n",
      "  Evaluation metric (bigger): True\n",
      "  Evaluation batch size: 8192\n",
      "  Evaluator: <hopwise.evaluator.evaluator.Evaluator object at 0x7e91c8406b90>\n",
      "  Collector: <hopwise.evaluator.collector.Collector object at 0x7e91c8429d10>\n"
     ]
    }
   ],
   "source": [
    "print(f\"  Evaluation step: {trainer.eval_step}\")\n",
    "print(f\"  Evaluation metric: {trainer.valid_metric}\")\n",
    "print(f\"  Evaluation metric (bigger): {trainer.valid_metric_bigger}\")\n",
    "print(f\"  Evaluation batch size: {trainer.test_batch_size}\")\n",
    "print(f\"  Evaluator: {trainer.evaluator}\")\n",
    "print(f\"  Collector: {trainer.eval_collector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "85b70252f84845a9bad9d1100f28a429",
      "c59c63eaa98e41a7ab94e54cf9e00a00"
     ]
    },
    "id": "E28SFPU8Lg6d",
    "outputId": "d010bd75-aa05-4431-d242-0d0e6ba80639"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b70252f84845a9bad9d1100f28a429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('recall@5', np.float64(0.039)),\n",
       "             ('recall@10', np.float64(0.0813)),\n",
       "             ('recall@20', np.float64(0.1352)),\n",
       "             ('ndcg@5', np.float64(0.0991)),\n",
       "             ('ndcg@10', np.float64(0.1006)),\n",
       "             ('ndcg@20', np.float64(0.1094))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = trainer.evaluate(test_data, load_best_model=True, model_file=None, show_progress=config[\"show_progress\"])\n",
    "test_result\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bae7bef979645f287afa6fbec5edab3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e302b4ad9534e769b9844fb3617e1e8": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_0bae7bef979645f287afa6fbec5edab3",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u001b[1;35mTrain     0\u001b[0m<span style=\"color: #800080; text-decoration-color: #800080\">  97%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span> <span style=\"color: #008000; text-decoration-color: #008000\">38/39 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:20</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">2 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[1;35mTrain     0\u001b[0m\u001b[35m  97%\u001b[0m \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚ï∏\u001b[0m\u001b[38;5;237m‚îÅ\u001b[0m \u001b[32m38/39 \u001b[0m [ \u001b[33m0:00:20\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m2 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "45edb2d761e94167a237db542e80534b": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_4d22c04d257949a39716ada0f26aab11",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u001b[1;35mTrain     0\u001b[0m<span style=\"color: #800080; text-decoration-color: #800080\">  98%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ï∏</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ</span> <span style=\"color: #008000; text-decoration-color: #008000\">44/45 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:17</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">3 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[1;35mTrain     0\u001b[0m\u001b[35m  98%\u001b[0m \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;2;249;38;114m‚ï∏\u001b[0m\u001b[38;5;237m‚îÅ\u001b[0m \u001b[32m44/45 \u001b[0m [ \u001b[33m0:00:17\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m3 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "4d22c04d257949a39716ada0f26aab11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c8cf91746cd45029b2b88875136b7c2": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_93e1f78976534166b5eb54b9e41d0686",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u001b[1;35mEvaluate   \u001b[0m<span style=\"color: #800080; text-decoration-color: #800080\">  66%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚ï∫‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #008000; text-decoration-color: #008000\">156/236 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">511 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[1;35mEvaluate   \u001b[0m\u001b[35m  66%\u001b[0m \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;5;237m‚ï∫\u001b[0m\u001b[38;5;237m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m156/236 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m511 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "85b70252f84845a9bad9d1100f28a429": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_c59c63eaa98e41a7ab94e54cf9e00a00",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\u001b[1;35mEvaluate   \u001b[0m<span style=\"color: #800080; text-decoration-color: #800080\">  73%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚ï∫‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #008000; text-decoration-color: #008000\">173/236 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:00:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">629 it/s</span> ]\n</pre>\n",
         "text/plain": "\u001b[1;35mEvaluate   \u001b[0m\u001b[35m  73%\u001b[0m \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;5;237m‚ï∫\u001b[0m\u001b[38;5;237m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m173/236 \u001b[0m [ \u001b[33m0:00:00\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m629 it/s\u001b[0m ]\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "93e1f78976534166b5eb54b9e41d0686": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c59c63eaa98e41a7ab94e54cf9e00a00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
